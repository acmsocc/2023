stoica:
    name: 'Ion Stoica (UC Berkeley)'
    # title: 'Scalable Input Data Processing for Resource-Efficient Machine Learning' 
    abstract: 'Technology ecosystems often undergo significant transformations as they mature. For example, telephony, the Internet, and PCs all started with a single provider, but each is now served by a competitive market that uses comprehensive technology standards to ensure compatibility. We believe that the cloud ecosystem, only fifteen years old, is on the verge of a similar transformation, driven by users desires for access to best-of-breed services and hardware, as well as enhanced availability, cost, performance, and security. In this talk, I will present our view on how todays cloud ecosystem could experience this transformation and discuss our early results and experiences in this endeavor.' 
    bio1: "Ion Stoica is a Professor in the EECS Department at the University of California at Berkeley, where he holds the Xu Bao Chancellor's Chair and is leading Sky Computing Lab (https://sky.cs.berkeley.edu/). He is currently doing research on cloud computing and AI systems. Current and past work includes Ray, Apache Spark, Apache Mesos, Tachyon, Chord DHT, and Dynamic Packet State (DPS). He is an ACM Fellow, Honorary Member of the Romanian Academy of Sciences, and has received numerous awards, including the Mark Weiser Award (2019), SIGOPS Hall of Fame Award (2015), and several \"Test of Time\" awards. He also co-founded several companies, including Anyscale (2019), Databricks (2013) and Conviva (2006)."

kozyrakis:
    name: 'Christos Kozyrakis (Stanford)'
    title: 'Cloud computing research in the era of machine learning '
    abstract: "The contemporary form of cloud computing is approaching its 18th anniversary. During this period, careful co-design of systems software and hardware brought substantial efficiency gains for both application developers and cloud operators. Most newly developed applications are now designed to be cloud native and there is a steady trend of migrating existing workloads to the cloud. This talk will focus on emerging challenges and opportunities for cloud computing research as we enter its adulthood phase. In particular, we will discuss how the growing prevalence machine learning workloads alters the demands placed on cloud systems.  The most significant change is the necessity to broaden the co-design approach to encompass the applications themselves."
    bio1: "Christos Kozyrakis is a Professor of Electrical Engineering and Computer Science at Stanford University. He is also the faculty director of the Stanford Platform Lab. Christos specializes in computer architecture and systems software design. His current research focuses on cloud computing, systems for machine learning, and machine learning for systems. Christos holds a BS degree from the University of Crete and a PhD degree from the University of California at Berkeley. He is a fellow of the ACM and the IEEE. He has received the ACM SIGARCH Maurice Wilkes Award, the ISCA Influential Paper Award, the NSF Career Award, the Okawa Foundation Research Grant, and faculty awards by IBM, Microsoft, and Google."

    
brooker:
    name: 'Marc Brooker (AWS)'
    # title: 'Systems for ML and ML for Systems:  A Virtuous Cycle'
    # abstract: "This talk is about the virtuous interplay between machine learning (ML) and systems. I will show examples of how systems optimized for ML computation can be used to train more accurate and capable ML models and how these ML models can be used to improve upon the ad-hoc heuristics used in system design and management. These improved systems can then be used to train better ML models. The latest trend in ML is the development of Foundation models. Foundation models are large pretrained models that have obtained state-of-the-art quality in natural language processing, vision, speech, and other areas. These models are challenging to train and serve because they are characterized by billions of parameters, irregular data access (sparsity) and irregular control flow. I will explain how Reconfigurable Dataflow Accelerators (RDAs) can be designed to accelerate foundation models with these characteristics. SambaNova Systems is using RDA technology to achieve record-setting performance on foundation models.  I will describe how the RDAs can also be used to build Taurus, an intelligent network data plane that enables ML models to be used to manage computer networks at full line-rate bandwidths. In particular, a Taurus prototype detects two orders of magnitude more events in a security application than a state-of-the-art system based on conventional network technology."
    # bio1: "Kunle Olukotun is the Cadence Design Professor of Electrical Engineering and Computer Science at Stanford University. Olukotun is a pioneer in multicore processor design and the leader of the Stanford Hydra chip multiprocessor (CMP) research project. He founded Afara Websystems to develop high-throughput, low-power multicore processors for server systems. The Afara multi-core processor, called Niagara, was acquired by Sun Microsystems and now powers Oracle's SPARC-based servers. In 2017, Olukotun co-founded SambaNova Systems, a Machine Learning and Artificial Intelligence company, and continues to lead as their Chief Technologist. Olukotun is the Director of the Pervasive Parallel Lab and a member of the Data Analytics tor What's Next (DAWN) Lab, developing infrastructure for usable machine learning. He is a member of the National Academy of Engineering, an ACM Fellow, and an IEEE Fellow for contributions to multiprocessors on a chip design and the commercialization of this technology. He also received the Harry H. Goode Memorial Award.  Olukotun received his Ph.D. in Computer Engineering from The University of Michigan."

tan:
    name: 'Wang-Chiew Tan (Facebook AI)'
    title: 'Querying Unstructured and Structured Data with Large Language Models'
    abstract: "Recently, Large Language Models (LLMs) have emerged as a powerful tool for accessing parametric knowledge, but the potential of effectively tapping into the vast expanse of external or private data remains largely unexplored. This talk presents an open-source question-answering system for seamlessly integrating model parameters with knowledge from external data sources to enhance its predictive capabilities.  Our larger vision transcends question answering. We envision a personal insight assistant, adept at sifting through one's past data to offer invaluable insights to help one make informed decisions and plan with foresight."
    bio1: "Wang-Chiew is a research scientist at Meta AI. Before she was the Head of Research at Megagon Labs, where she led the research efforts on building advanced technologies to enhance search by experience. Prior to joining Megagon Labs, she was a Professor of Computer Science at the University of California, Santa Cruz. She also spent two years at IBM Research - Almaden. She co-authored best papers, she is a co-recipient of the 2014 ACM PODS Alberto O. Mendelzon Test-of-Time Award, the 2018 ICDT Test-of-Time Award, and the 2020 Alonzo Church Award. She received the 2019 VLDB Women in Database Research Award, the 2021 National University of Singapore Outstanding Computing Alumni Award, and she is a Fellow of the ACM."